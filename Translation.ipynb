{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8c69ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Inaya\\Documents\\GitHub\\projet_transalation\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Inaya\\Documents\\GitHub\\projet_transalation\\venv\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:177: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Inaya\\AppData\\Local\\Temp\\ipykernel_12116\\3679597211.py:43: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  return ChatOllama(model=model_name, temperature=temperature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 1/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 1/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 1/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 1/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 1/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 1/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 1/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 1/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 1/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 1/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 1/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 1/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 1/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 1/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 1/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 1/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 1/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 2/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 2/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 2/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 2/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 2/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 2/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 2/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 2/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 2/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 2/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 2/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 2/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 2/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 2/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 2/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 2/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 2/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 2/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 3/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 3/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 3/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 3/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 3/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 3/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 3/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 3/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 3/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 3/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 3/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 3/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 3/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 3/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 3/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 3/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 3/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 3/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 4/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 4/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 4/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 4/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 4/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 4/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 4/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 4/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 4/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 4/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 4/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 4/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 4/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 4/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 4/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 4/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 4/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 4/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 5/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 5/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 5/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 5/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 5/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 5/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 5/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 5/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 5/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 5/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 5/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 5/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 5/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 5/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 5/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 5/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 5/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 5/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 6/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 6/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 6/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 6/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 6/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 6/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 6/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 6/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 6/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 6/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 6/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 6/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 6/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 6/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 6/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 6/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 6/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 6/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 7/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 7/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 7/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 7/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 7/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 7/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 7/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 7/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 7/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 7/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 7/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 7/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 7/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 7/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 7/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 7/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 7/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 7/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 8/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 8/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 8/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 8/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 8/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 8/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 8/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 8/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 8/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 8/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 8/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 8/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 8/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 8/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 8/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 8/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 8/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 8/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 9/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 9/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 9/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 9/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 9/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 9/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 9/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 9/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 9/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 9/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 9/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 9/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 9/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 9/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 9/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 9/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 9/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 9/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 10/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 10/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 10/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 10/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 10/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 10/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 10/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 10/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 10/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 10/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 10/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 10/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 10/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 10/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 10/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 10/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 10/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 10/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 11/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 11/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 11/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 11/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 11/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 11/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 11/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 11/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 11/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 11/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 11/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 11/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 11/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 11/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 11/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 11/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 11/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 11/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 12/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 12/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 12/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 12/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 12/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 12/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 12/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 12/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 12/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 12/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 12/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 12/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 12/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 12/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 12/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 12/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 12/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 12/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 13/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 13/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 13/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 13/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 13/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 13/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 13/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 13/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 13/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 13/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 13/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 13/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 13/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 13/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 13/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 13/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 13/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 13/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 14/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 14/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 14/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 14/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 14/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 14/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 14/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 14/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 14/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 14/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 14/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 14/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 14/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 14/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 14/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 14/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 14/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 14/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 15/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 15/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 15/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 15/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 15/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 15/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 15/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 15/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 15/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 15/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 15/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 15/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 15/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 15/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 15/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 15/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 15/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 15/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 16/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 16/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 16/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 16/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 16/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 16/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 16/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 16/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 16/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 16/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 16/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 16/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 16/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 16/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 16/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 16/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 16/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 16/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 17/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 17/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 17/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 17/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 17/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 17/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 17/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 17/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 17/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 17/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 17/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 17/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 17/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 17/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 17/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 17/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 17/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 17/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 18/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 18/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 18/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 18/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 18/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 18/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 18/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 18/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 18/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 18/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 18/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 18/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 18/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 18/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 18/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 18/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 18/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 18/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 19/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 19/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 19/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 19/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 19/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 19/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 19/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 19/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 19/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 19/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 19/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 19/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 19/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 19/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 19/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 19/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 19/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 19/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 20/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 20/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 20/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 20/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 20/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 20/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 20/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 20/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 20/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 20/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 20/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 20/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 20/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 20/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 20/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 20/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 20/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 20/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 21/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 21/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 21/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 21/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 21/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 21/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 21/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 21/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 21/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 21/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 21/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 21/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 21/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 21/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 21/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 21/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 21/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 21/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 22/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 22/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 22/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 22/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 22/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 22/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 22/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 22/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 22/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 22/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 22/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 22/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 22/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 22/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 22/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 22/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 22/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 22/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 23/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 23/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 23/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 23/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 23/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 23/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 23/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 23/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 23/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 23/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 23/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 23/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 23/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 23/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 23/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 23/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 23/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 23/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 24/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 24/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 24/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 24/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 24/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 24/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 24/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 24/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 24/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 24/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 24/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 24/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 24/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 24/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 24/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 24/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 24/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 24/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 25/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 25/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 25/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 25/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 25/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 25/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 25/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 25/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 25/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 25/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 25/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 25/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 25/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 25/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 25/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 25/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 25/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 25/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 26/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 26/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 26/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 26/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 26/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 26/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 26/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 26/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 26/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 26/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 26/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 26/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 26/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 26/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 26/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 26/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 26/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 26/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 27/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 27/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 27/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 27/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 27/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 27/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 27/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 27/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 27/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 27/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 27/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 27/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 27/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 27/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 27/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 27/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 27/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 27/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 28/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 28/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 28/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 28/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 28/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 28/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 28/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 28/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 28/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 28/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 28/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 28/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 28/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 28/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 28/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 28/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 28/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 28/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 28/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 28/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 29/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 29/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 29/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 29/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 29/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 29/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 29/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 29/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 29/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 29/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 29/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 29/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 29/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 29/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 29/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 29/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 29/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 29/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 29/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 29/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 30/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 30/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 30/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 30/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 30/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 30/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 30/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 30/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 30/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 30/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 30/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 30/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 30/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 30/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 30/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 30/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 30/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 30/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 30/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 30/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 31/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 31/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 31/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 31/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 31/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 31/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 31/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 31/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 31/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 31/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 31/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 31/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 31/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 31/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 31/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 31/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 31/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 31/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 32/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 32/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 32/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 32/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 32/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 32/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 32/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 32/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 32/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 32/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 32/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 32/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 32/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 32/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 32/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 32/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 32/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 32/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 33/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 33/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 33/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 33/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 33/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 33/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 33/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 33/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 33/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 33/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 33/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 33/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 33/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 33/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 33/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 33/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 33/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 33/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 33/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 33/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 34/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 34/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 34/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 34/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 34/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 34/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 34/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 34/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 34/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 34/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 34/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 34/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 34/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 34/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 34/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 34/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 34/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 34/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 35/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 35/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 35/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 35/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 35/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 35/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 35/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 35/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 35/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 35/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 35/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 35/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 35/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 35/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 35/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 35/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 35/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 35/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 35/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 35/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 36/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 36/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 36/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 36/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 36/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 36/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 36/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 36/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 36/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 36/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 36/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 36/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 36/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 36/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 36/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 36/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 36/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 36/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 36/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 36/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 37/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 37/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 37/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 37/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 37/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 37/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 37/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 37/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 37/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 37/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 37/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 37/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 37/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 37/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 37/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 37/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 37/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 37/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 37/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 37/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 38/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 38/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 38/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 38/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 38/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 38/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 38/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 38/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 38/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 38/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 38/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 38/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 38/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 38/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 38/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 38/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 38/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 38/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 38/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 38/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 39/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 39/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 39/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 39/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 39/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 39/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 39/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 39/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 39/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 39/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 39/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 39/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 39/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 39/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 39/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 39/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 39/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 39/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 39/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 39/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 40/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 40/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 40/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 40/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 40/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 40/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 40/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 40/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 40/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 40/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 40/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 40/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 40/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 40/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 40/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 40/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 40/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 40/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 40/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 40/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 41/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 41/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 41/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 41/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 41/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 41/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 41/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 41/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 41/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 41/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 41/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 41/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 41/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 41/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 41/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 41/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 41/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 41/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 41/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 41/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 42/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 42/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 42/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 42/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 42/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 42/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 42/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 42/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 42/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 42/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 42/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 42/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 42/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 42/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 42/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 42/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 42/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 42/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 42/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 42/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 43/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 43/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 43/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 43/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 43/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 43/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 43/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 43/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 43/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 43/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 43/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 43/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 43/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 43/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 43/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 43/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 43/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 43/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 43/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 43/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 44/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 44/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 44/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 44/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 44/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 44/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 44/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 44/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 44/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 44/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 44/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 44/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 44/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 44/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 44/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 44/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 44/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 44/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 44/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 44/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 45/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 45/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 45/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 45/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 45/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 45/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 45/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 45/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 45/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 45/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 45/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 45/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 45/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 45/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 45/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 45/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 45/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 45/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 45/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 45/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 46/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 46/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 46/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 46/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 46/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 46/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 46/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 46/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 46/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 46/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 46/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 46/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 46/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 46/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 46/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 46/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 46/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 46/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 46/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 46/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 47/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 47/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 47/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 47/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 47/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 47/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 47/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 47/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 47/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 47/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 47/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 47/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 47/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 47/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 47/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 47/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 47/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 47/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 47/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 47/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 48/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 48/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 48/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 48/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 48/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 48/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 48/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 48/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 48/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 48/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 48/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 48/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 48/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 48/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 48/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 48/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 48/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 48/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 48/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 48/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 49/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 49/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 49/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 49/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 49/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 49/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 49/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 49/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 49/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 49/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 49/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 49/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 49/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 49/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 49/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 49/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 49/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 49/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 49/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 49/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0 | Example 50/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.2 | Example 50/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.5 | Example 50/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 0.8 | Example 50/50\n",
      "Ollama - Model: tinyllama:1.1b | Temp: 1.0 | Example 50/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0 | Example 50/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.2 | Example 50/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.5 | Example 50/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 0.8 | Example 50/50\n",
      "Ollama - Model: qwen2.5:0.5b | Temp: 1.0 | Example 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0 | Example 50/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.2 | Example 50/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.5 | Example 50/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 0.8 | Example 50/50\n",
      "Hugging Face - Model: Helsinki-NLP/opus-mt-fr-en | Temp: 1.0 | Example 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0 | Example 50/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.2 | Example 50/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.5 | Example 50/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 0.8 | Example 50/50\n",
      "Hugging Face - Model: facebook/wmt19-fr-en | Temp: 1.0 | Example 50/50\n",
      " valuation termine et sauvegarde dans evaluation_translations.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from rouge_score import rouge_scorer\n",
    "import sacrebleu\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.messages import HumanMessage\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Chargement spacy pour tokenization\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def tokenize(text):\n",
    "    return [token.text for token in nlp(text)]\n",
    "\n",
    "def evaluate(reference, generated):\n",
    "    ref_tokens = tokenize(reference)\n",
    "    gen_tokens = tokenize(generated)\n",
    "\n",
    "    bleu = sacrebleu.sentence_bleu(\" \".join(gen_tokens), [\" \".join(ref_tokens)]).score\n",
    "\n",
    "    scorer = rouge_scorer.RougeScorer([\"rouge1\", \"rougeL\"], use_stemmer=True)\n",
    "    scores = scorer.score(reference, generated)\n",
    "\n",
    "    return bleu, scores[\"rouge1\"].fmeasure, scores[\"rougeL\"].fmeasure\n",
    "\n",
    "# Chargement modle Hugging Face FR->EN\n",
    "hf_model_name = \"Helsinki-NLP/opus-mt-fr-en\"\n",
    "tokenizer_hf = MarianTokenizer.from_pretrained(hf_model_name)\n",
    "model_hf = MarianMTModel.from_pretrained(hf_model_name)\n",
    "\n",
    "def generate_hf(texts, temperature=0.0):\n",
    "    inputs = tokenizer_hf(texts, return_tensors=\"pt\", padding=True)\n",
    "    outputs = model_hf.generate(\n",
    "        **inputs,\n",
    "        do_sample=True if temperature > 0 else False,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    translations = [tokenizer_hf.decode(t, skip_special_tokens=True) for t in outputs]\n",
    "    return translations\n",
    "\n",
    "def create_ollama_model(model_name, temperature):\n",
    "    return ChatOllama(model=model_name, temperature=temperature)\n",
    "\n",
    "def generate_ollama(model, text):\n",
    "    prompt = f\"Translate this French sentence to English:\\n\\n\\\"{text}\\\"\"\n",
    "    try:\n",
    "        response = model.invoke([HumanMessage(content=prompt)])\n",
    "        return response.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error during model call: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def generate_translation(model_name, temperature, text, framework=\"ollama\"):\n",
    "    \"\"\"\n",
    "    framework: \"ollama\" or \"hf\"\n",
    "    \"\"\"\n",
    "    if framework == \"hf\":\n",
    "        # HuggingFace attend une liste\n",
    "        return generate_hf([text], temperature=temperature)[0]\n",
    "    elif framework == \"ollama\":\n",
    "        model = create_ollama_model(model_name, temperature)\n",
    "        return generate_ollama(model, text)\n",
    "    else:\n",
    "        raise ValueError(\"framework must be 'ollama' or 'hf'\")\n",
    "\n",
    "# --- Paramtres ---\n",
    "\n",
    "models_ollama = [\"tinyllama:1.1b\", \"qwen2.5:0.5b\"]\n",
    "models_hf = [\"Helsinki-NLP/opus-mt-fr-en\", \"facebook/wmt19-fr-en\"]\n",
    "temperatures = [0, 0.2, 0.5, 0.8, 1.0]\n",
    "\n",
    "# Exemple de DataFrame avec colonnes : 'fr' (phrase franaise) et 'en' (rfrence anglaise)\n",
    "df_data = pd.read_csv(\"sample_fr_en_clean.csv\").head(50)\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, row in df_data.iterrows():\n",
    "    original = row[\"fr\"]\n",
    "    reference = row[\"en\"]\n",
    "\n",
    "    # Ollama\n",
    "    for model_name in models_ollama:\n",
    "        for temp in temperatures:\n",
    "            print(f\"Ollama - Model: {model_name} | Temp: {temp} | Example {i+1}/{len(df_data)}\")\n",
    "            generated = generate_translation(model_name, temp, original, framework=\"ollama\")\n",
    "            bleu, rouge1, rougeL = evaluate(reference, generated)\n",
    "            results.append({\n",
    "                \"example_id\": i,\n",
    "                \"model\": model_name,\n",
    "                \"temperature\": temp,\n",
    "                \"original\": original,\n",
    "                \"reference\": reference,\n",
    "                \"translation\": generated,\n",
    "                \"BLEU\": bleu,\n",
    "                \"ROUGE-1\": rouge1,\n",
    "                \"ROUGE-L\": rougeL,\n",
    "                \"framework\": \"ollama\"\n",
    "            })\n",
    "            time.sleep(1)  # viter surcharge\n",
    "\n",
    "    # Hugging Face\n",
    "    for model_name in models_hf:\n",
    "        for temp in temperatures:\n",
    "            print(f\"Hugging Face - Model: {model_name} | Temp: {temp} | Example {i+1}/{len(df_data)}\")\n",
    "            generated = generate_translation(model_name, temp, original, framework=\"hf\")\n",
    "            bleu, rouge1, rougeL = evaluate(reference, generated)\n",
    "            results.append({\n",
    "                \"example_id\": i,\n",
    "                \"model\": model_name,\n",
    "                \"temperature\": temp,\n",
    "                \"original\": original,\n",
    "                \"reference\": reference,\n",
    "                \"translation\": generated,\n",
    "                \"BLEU\": bleu,\n",
    "                \"ROUGE-1\": rouge1,\n",
    "                \"ROUGE-L\": rougeL,\n",
    "                \"framework\": \"huggingface\"\n",
    "            })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(\"evaluation_translations.csv\", index=False)\n",
    "\n",
    "print(\" valuation termine et sauvegarde dans evaluation_translations.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
